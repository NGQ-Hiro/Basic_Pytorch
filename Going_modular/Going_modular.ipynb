{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-waU-s8sJXpW"
   },
   "source": [
    "# 0. Create folder going_modular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 576,
     "status": "ok",
     "timestamp": 1736782022084,
     "user": {
      "displayName": "Hiệu Ngô Quang",
      "userId": "01591528706159515171"
     },
     "user_tz": -420
    },
    "id": "BGjjrIncJcmZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('going_modular'):\n",
    "    os.mkdir('going_modular')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsIjuOd-1G6L"
   },
   "source": [
    "# 1. Get Data from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1736782022488,
     "user": {
      "displayName": "Hiệu Ngô Quang",
      "userId": "01591528706159515171"
     },
     "user_tz": -420
    },
    "id": "knacYgTq1Pbg",
    "outputId": "d65c9601-1391-4539-84d0-7c8825b48ebf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find data/pizza_steak_sushi directory, creating one...\n",
      "Downloading pizza, steak, sushi data...\n",
      "Unzipping pizza, steak, sushi data...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup path to data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it...\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download pizza, steak, sushi data\n",
    "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "    print(\"Downloading pizza, steak, sushi data...\")\n",
    "    f.write(request.content)\n",
    "\n",
    "# Unzip pizza, steak, sushi data\n",
    "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "    print(\"Unzipping pizza, steak, sushi data...\")\n",
    "    zip_ref.extractall(image_path)\n",
    "\n",
    "# Remove zip file\n",
    "os.remove(data_path / \"pizza_steak_sushi.zip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gmw9jbG1Sta"
   },
   "source": [
    "# 2. Create Datsets and DataLoaders (data_setup.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1736782022488,
     "user": {
      "displayName": "Hiệu Ngô Quang",
      "userId": "01591528706159515171"
     },
     "user_tz": -420
    },
    "id": "jldX_uUY1gwJ",
    "outputId": "9be393d1-59e2-4cd4-e240-7c052828a566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/data_setup.py\n",
    "\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_dir: str,\n",
    "    test_dir: str,\n",
    "    transform: transforms.Compose,\n",
    "    batch_size: int,\n",
    "    num_workers: int=NUM_WORKERS\n",
    "):\n",
    "   # Use ImageFolder to create dataset(s)\n",
    "  train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "  test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "  # Get class names\n",
    "  class_names = train_data.classes\n",
    "\n",
    "  # Turn images into data loaders\n",
    "  train_dataloader = DataLoader(\n",
    "      train_data,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=True,\n",
    "      num_workers=num_workers,\n",
    "      pin_memory=True,\n",
    "  )\n",
    "  test_dataloader = DataLoader(\n",
    "      test_data,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=False, # don't need to shuffle test data\n",
    "      num_workers=num_workers,\n",
    "      pin_memory=True,\n",
    "  )\n",
    "\n",
    "  return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBEiIn0k203X"
   },
   "source": [
    "## Using the function within data_set.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8363,
     "status": "ok",
     "timestamp": 1736782030848,
     "user": {
      "displayName": "Hiệu Ngô Quang",
      "userId": "01591528706159515171"
     },
     "user_tz": -420
    },
    "id": "uoqJnaLm29OU"
   },
   "outputs": [],
   "source": [
    "from going_modular import data_setup\n",
    "from torchvision import transforms\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=data_transform,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3YVUmPr13Zw"
   },
   "source": [
    "# 3. Making a model (model_builder.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1736782030848,
     "user": {
      "displayName": "Hiệu Ngô Quang",
      "userId": "01591528706159515171"
     },
     "user_tz": -420
    },
    "id": "znCTqMeG170D",
    "outputId": "232e2917-5879-4583-f2f6-04b87f90e8f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/model_builder.py\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "  \"\"\"Creates the TinyVGG architecture.\n",
    "\n",
    "  Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n",
    "  See the original architecture here: https://poloclub.github.io/cnn-explainer/\n",
    "\n",
    "  Args:\n",
    "    input_shape: An integer indicating number of input channels.\n",
    "    hidden_units: An integer indicating number of hidden units between layers.\n",
    "    output_shape: An integer indicating number of output units.\n",
    "  \"\"\"\n",
    "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "      super().__init__()\n",
    "      self.conv_block_1 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=input_shape,\n",
    "                    out_channels=hidden_units,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=0),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(in_channels=hidden_units,\n",
    "                    out_channels=hidden_units,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=0),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(kernel_size=2,\n",
    "                        stride=2)\n",
    "      )\n",
    "      self.conv_block_2 = nn.Sequential(\n",
    "          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(2)\n",
    "      )\n",
    "      self.classifier = nn.Sequential(\n",
    "          nn.Flatten(),\n",
    "          # Where did this in_features shape come from?\n",
    "          # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
    "          nn.Linear(in_features=hidden_units*13*13,\n",
    "                    out_features=output_shape)\n",
    "      )\n",
    "\n",
    "  def forward(self, x: torch.Tensor):\n",
    "      return self.classifier(self.conv_block_2(self.conv_block_1(x))) # <- leverage the benefits of operator fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORfMF8K62Nx9"
   },
   "source": [
    "## Create model and set up to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 371,
     "status": "ok",
     "timestamp": 1736782031216,
     "user": {
      "displayName": "Hiệu Ngô Quang",
      "userId": "01591528706159515171"
     },
     "user_tz": -420
    },
    "id": "FQ-incke2SxG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from going_modular import model_builder\n",
    "\n",
    "# Set up device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Create model\n",
    "torch.manual_seed(42)\n",
    "model = model_builder.TinyVGG(input_shape=3,\n",
    "                                hidden_units=10,\n",
    "                                output_shape=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ounUyuC22eNe"
   },
   "source": [
    "# 4. Creating train_step() and test_step() functions and train() to combine them engine.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIb-0mFl6kXL"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1736782031216,
     "user": {
      "displayName": "Hiệu Ngô Quang",
      "userId": "01591528706159515171"
     },
     "user_tz": -420
    },
    "id": "1XTf_GFp3pwX",
    "outputId": "b59b0105-e7a5-496d-c211-8819d73008bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/engine.py\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "# from timeit import default_timer as timer\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "\n",
    "    # Setup train loss, train accuracy\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    # Loop through data loader data batches\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "      # Send x, y to device\n",
    "      x, y = x.to(device), y.to(device)\n",
    "\n",
    "      # Forward\n",
    "      y_pred = model(x)\n",
    "\n",
    "      # Calculate loss\n",
    "      loss = loss_fn(y_pred, y)\n",
    "      train_loss += loss.item()\n",
    "\n",
    "      # Optimizer zero grad\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # Loss backward\n",
    "      loss.backward()\n",
    "\n",
    "      # Optimizer step\n",
    "      optimizer.step()\n",
    "\n",
    "      # Calculate accuracy\n",
    "      y_pred_class = torch.argmax(y_pred, dim=1)\n",
    "      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    # Average loss and accuracy per batch\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "  # Put model in eval mode\n",
    "  model.eval()\n",
    "\n",
    "  # Set up test loss, test accuracy\n",
    "  test_loss, test_acc = 0, 0\n",
    "\n",
    "  # Turn on inference mode\n",
    "  with torch.inference_mode():\n",
    "    # Loop through data loader batches\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "      # Send x, y to device\n",
    "      x, y = x.to(device), y.to(device)\n",
    "\n",
    "      # Forwardind\n",
    "      y_logits = model(x)\n",
    "\n",
    "      # Calculate and accumulate loss\n",
    "      loss = loss_fn(y_logits, y)\n",
    "      test_loss += loss.item()\n",
    "\n",
    "      # Calculate and accumulate accuracy\n",
    "      y_pred = torch.argmax(y_logits, dim=1)\n",
    "      test_acc += (y_pred == y).sum().item()/len(y_pred)\n",
    "\n",
    "  # Calculate loss and accuracy per batch\n",
    "  test_loss /= len(dataloader)\n",
    "  test_acc /= len(dataloader)\n",
    "  return test_loss, test_acc\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, list]:\n",
    "  # Create empty results dictionary\n",
    "  results ={\n",
    "      'train_loss': [],\n",
    "      'train_acc': [],\n",
    "      'test_loss': [],\n",
    "      'test_acc': []\n",
    "  }\n",
    "\n",
    "  # Loop through training and testing steps for numbers of epochs\n",
    "  for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_acc = train_step(model=model,\n",
    "                                       dataloader=train_dataloader,\n",
    "                                       loss_fn=loss_fn,\n",
    "                                       optimizer=optimizer,\n",
    "                                       device=device)\n",
    "    test_loss, test_acc = test_step(model=model,\n",
    "                                    dataloader=test_dataloader,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    device=device)\n",
    "    # Print result per epoch\n",
    "    print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "      )\n",
    "\n",
    "    # Update results dictionary\n",
    "    results[\"train_loss\"].append(train_loss)\n",
    "    results[\"train_acc\"].append(train_acc)\n",
    "    results[\"test_loss\"].append(test_loss)\n",
    "    results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432,
     "referenced_widgets": [
      "3fc3dd1e74a745af922e0fe31cf7a1e7",
      "f9f827f31aa240c1ab863dd902e7be1b",
      "4091b78c58f64e8196aa246e4bb6dead",
      "f5a397087e98477cbe22634788647d0e",
      "e41353bad3f9441dad21552bd6dc22d6",
      "e7cccf725be740c5a6613f32aa8492d3",
      "be51040f53c54258aa214d80a6414792",
      "21850a6132bf452eacfec130c16b1152",
      "70efd21fa39c4322a362197155eb587a",
      "680983e0b2fe4e08ae1c86367d9e725c",
      "5344144a8b5b40cdbc1533538d020f7f"
     ]
    },
    "executionInfo": {
     "elapsed": 8580,
     "status": "ok",
     "timestamp": 1736782039793,
     "user": {
      "displayName": "Hiệu Ngô Quang",
      "userId": "01591528706159515171"
     },
     "user_tz": -420
    },
    "id": "Z9b2P00S6m9I",
    "outputId": "2480082e-b690-4b0a-f5f1-b25baae9c83a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc3dd1e74a745af922e0fe31cf7a1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.1063 | train_acc: 0.3047 | test_loss: 1.0983 | test_acc: 0.3011\n",
      "Epoch: 2 | train_loss: 1.0998 | train_acc: 0.3281 | test_loss: 1.0697 | test_acc: 0.5417\n",
      "Epoch: 3 | train_loss: 1.0869 | train_acc: 0.4883 | test_loss: 1.0808 | test_acc: 0.4924\n",
      "Epoch: 4 | train_loss: 1.0843 | train_acc: 0.4023 | test_loss: 1.0608 | test_acc: 0.5833\n",
      "Epoch: 5 | train_loss: 1.0663 | train_acc: 0.4102 | test_loss: 1.0654 | test_acc: 0.5644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [1.1063191592693329,\n",
       "  1.0998024493455887,\n",
       "  1.086867794394493,\n",
       "  1.0843190401792526,\n",
       "  1.066251888871193],\n",
       " 'train_acc': [0.3046875, 0.328125, 0.48828125, 0.40234375, 0.41015625],\n",
       " 'test_loss': [1.0983209212621052,\n",
       "  1.0696990092595418,\n",
       "  1.0807570616404216,\n",
       "  1.0607832272847493,\n",
       "  1.0654252370198567],\n",
       " 'test_acc': [0.30113636363636365,\n",
       "  0.5416666666666666,\n",
       "  0.49242424242424243,\n",
       "  0.5833333333333334,\n",
       "  0.5643939393939394]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from going_modular import engine\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "engine.train(model=model,\n",
    "           train_dataloader=train_dataloader,\n",
    "           test_dataloader=test_dataloader,\n",
    "           loss_fn=loss_fn,\n",
    "           optimizer=optimizer,\n",
    "           epochs=5,\n",
    "           device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeQWKecu8LAM"
   },
   "source": [
    "# 5. Creating function to save model (utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1736782039794,
     "user": {
      "displayName": "Hiệu Ngô Quang",
      "userId": "01591528706159515171"
     },
     "user_tz": -420
    },
    "id": "-sfcbhGP65Mu",
    "outputId": "c0c9e9bd-fc98-45ad-ca64-0a6dc5769970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/utils.py\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "def save_model(model: torch.nn.Module,\n",
    "             target_dir: str,\n",
    "             model_name: str):\n",
    "  target_dir_path = Path(target_dir)\n",
    "  target_dir_path.mkdir(parents=True,\n",
    "                        exist_ok=True)\n",
    "\n",
    "  model_save_path = target_dir_path / model_name\n",
    "\n",
    "  print(f'Saving model to: {model_save_path}')\n",
    "  torch.save(obj=model.state_dict(),\n",
    "             f=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1736782039794,
     "user": {
      "displayName": "Hiệu Ngô Quang",
      "userId": "01591528706159515171"
     },
     "user_tz": -420
    },
    "id": "R4W03Xh78yoG",
    "outputId": "ad58c7ae-e6b4-433d-ee81-76a7781f0ac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models/05_going_modular_script_mode_tinyvgg_model.pth\n"
     ]
    }
   ],
   "source": [
    "from going_modular import utils\n",
    "utils.save_model(model=model,\n",
    "                 target_dir='models',\n",
    "                 model_name='05_going_modular_script_mode_tinyvgg_model.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNwVvcz6DgZXlW4o1VrWUyX",
   "gpuType": "T4",
   "mount_file_id": "1YqCImSTl6X1s8Ac1PcckTBG9Fls-oa1h",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "21850a6132bf452eacfec130c16b1152": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fc3dd1e74a745af922e0fe31cf7a1e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f9f827f31aa240c1ab863dd902e7be1b",
       "IPY_MODEL_4091b78c58f64e8196aa246e4bb6dead",
       "IPY_MODEL_f5a397087e98477cbe22634788647d0e"
      ],
      "layout": "IPY_MODEL_e41353bad3f9441dad21552bd6dc22d6"
     }
    },
    "4091b78c58f64e8196aa246e4bb6dead": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21850a6132bf452eacfec130c16b1152",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_70efd21fa39c4322a362197155eb587a",
      "value": 5
     }
    },
    "5344144a8b5b40cdbc1533538d020f7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "680983e0b2fe4e08ae1c86367d9e725c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70efd21fa39c4322a362197155eb587a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "be51040f53c54258aa214d80a6414792": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e41353bad3f9441dad21552bd6dc22d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7cccf725be740c5a6613f32aa8492d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5a397087e98477cbe22634788647d0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_680983e0b2fe4e08ae1c86367d9e725c",
      "placeholder": "​",
      "style": "IPY_MODEL_5344144a8b5b40cdbc1533538d020f7f",
      "value": " 5/5 [00:08&lt;00:00,  1.54s/it]"
     }
    },
    "f9f827f31aa240c1ab863dd902e7be1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7cccf725be740c5a6613f32aa8492d3",
      "placeholder": "​",
      "style": "IPY_MODEL_be51040f53c54258aa214d80a6414792",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
