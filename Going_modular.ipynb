{"cells":[{"cell_type":"markdown","metadata":{"id":"-waU-s8sJXpW"},"source":["# 0. Create folder going_modular"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BGjjrIncJcmZ"},"outputs":[],"source":["import os\n","\n","if not os.path.exists('going_modular'):\n","    os.mkdir('going_modular')"]},{"cell_type":"markdown","metadata":{"id":"jsIjuOd-1G6L"},"source":["# 1. Get Data from url"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1076,"status":"ok","timestamp":1736855057748,"user":{"displayName":"","userId":""},"user_tz":-420},"id":"knacYgTq1Pbg","outputId":"154f24ab-65b0-4c9e-e494-3c95cab33f9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Did not find data/pizza_steak_sushi directory, creating one...\n","Downloading pizza, steak, sushi data...\n","Unzipping pizza, steak, sushi data...\n"]}],"source":["import os\n","import requests\n","import zipfile\n","from pathlib import Path\n","\n","# Setup path to data folder\n","data_path = Path(\"data/\")\n","image_path = data_path / \"pizza_steak_sushi\"\n","\n","# If the image folder doesn't exist, download it and prepare it...\n","if image_path.is_dir():\n","    print(f\"{image_path} directory exists.\")\n","else:\n","    print(f\"Did not find {image_path} directory, creating one...\")\n","    image_path.mkdir(parents=True, exist_ok=True)\n","\n","# Download pizza, steak, sushi data\n","with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n","    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n","    print(\"Downloading pizza, steak, sushi data...\")\n","    f.write(request.content)\n","\n","# Unzip pizza, steak, sushi data\n","with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n","    print(\"Unzipping pizza, steak, sushi data...\")\n","    zip_ref.extractall(image_path)\n","\n","# Remove zip file\n","os.remove(data_path / \"pizza_steak_sushi.zip\")\n"]},{"cell_type":"markdown","metadata":{"id":"9gmw9jbG1Sta"},"source":["# 2. Create Datsets and DataLoaders (data_setup.py)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1736855057748,"user":{"displayName":"","userId":""},"user_tz":-420},"id":"jldX_uUY1gwJ","outputId":"512fb7cc-1784-4dad-d69d-0e66c39bb21f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/data_setup.py\n"]}],"source":["%%writefile going_modular/data_setup.py\n","\n","import os\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","NUM_WORKERS = os.cpu_count()\n","\n","def create_dataloaders(\n","    train_dir: str,\n","    test_dir: str,\n","    transform: transforms.Compose,\n","    batch_size: int,\n","    num_workers: int=NUM_WORKERS\n","):\n","   # Use ImageFolder to create dataset(s)\n","  train_data = datasets.ImageFolder(train_dir, transform=transform)\n","  test_data = datasets.ImageFolder(test_dir, transform=transform)\n","\n","  # Get class names\n","  class_names = train_data.classes\n","\n","  # Turn images into data loaders\n","  train_dataloader = DataLoader(\n","      train_data,\n","      batch_size=batch_size,\n","      shuffle=True,\n","      num_workers=num_workers,\n","      pin_memory=True,\n","  )\n","  test_dataloader = DataLoader(\n","      test_data,\n","      batch_size=batch_size,\n","      shuffle=False, # don't need to shuffle test data\n","      num_workers=num_workers,\n","      pin_memory=True,\n","  )\n","\n","  return train_dataloader, test_dataloader, class_names"]},{"cell_type":"markdown","metadata":{"id":"iBEiIn0k203X"},"source":["## Using the function within data_set.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uoqJnaLm29OU"},"outputs":[],"source":["from going_modular import data_setup\n","from torchvision import transforms\n","train_dir = image_path / \"train\"\n","test_dir = image_path / \"test\"\n","\n","data_transform = transforms.Compose([\n","    transforms.Resize((64, 64)),\n","    transforms.ToTensor()\n","])\n","\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n","    train_dir=train_dir,\n","    test_dir=test_dir,\n","    transform=data_transform,\n","    batch_size=32\n",")"]},{"cell_type":"markdown","metadata":{"id":"Y3YVUmPr13Zw"},"source":["# 3. Making a model (model_builder.py)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1736855066716,"user":{"displayName":"","userId":""},"user_tz":-420},"id":"znCTqMeG170D","outputId":"c77a8f32-9586-4259-d865-5d63bd29632c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/model_builder.py\n"]}],"source":["%%writefile going_modular/model_builder.py\n","import torch\n","from torch import nn\n","\n","class TinyVGG(nn.Module):\n","  \"\"\"Creates the TinyVGG architecture.\n","\n","  Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n","  See the original architecture here: https://poloclub.github.io/cnn-explainer/\n","\n","  Args:\n","    input_shape: An integer indicating number of input channels.\n","    hidden_units: An integer indicating number of hidden units between layers.\n","    output_shape: An integer indicating number of output units.\n","  \"\"\"\n","  def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n","      super().__init__()\n","      self.conv_block_1 = nn.Sequential(\n","          nn.Conv2d(in_channels=input_shape,\n","                    out_channels=hidden_units,\n","                    kernel_size=3,\n","                    stride=1,\n","                    padding=0),\n","          nn.ReLU(),\n","          nn.Conv2d(in_channels=hidden_units,\n","                    out_channels=hidden_units,\n","                    kernel_size=3,\n","                    stride=1,\n","                    padding=0),\n","          nn.ReLU(),\n","          nn.MaxPool2d(kernel_size=2,\n","                        stride=2)\n","      )\n","      self.conv_block_2 = nn.Sequential(\n","          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n","          nn.ReLU(),\n","          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n","          nn.ReLU(),\n","          nn.MaxPool2d(2)\n","      )\n","      self.classifier = nn.Sequential(\n","          nn.Flatten(),\n","          # Where did this in_features shape come from?\n","          # It's because each layer of our network compresses and changes the shape of our inputs data.\n","          nn.Linear(in_features=hidden_units*13*13,\n","                    out_features=output_shape)\n","      )\n","\n","  def forward(self, x: torch.Tensor):\n","      return self.classifier(self.conv_block_2(self.conv_block_1(x))) # <- leverage the benefits of operator fusion"]},{"cell_type":"markdown","metadata":{"id":"ORfMF8K62Nx9"},"source":["## Create model and set up to device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FQ-incke2SxG"},"outputs":[],"source":["import torch\n","from going_modular import model_builder\n","\n","# Set up device\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# Create model\n","torch.manual_seed(42)\n","model = model_builder.TinyVGG(input_shape=3,\n","                                hidden_units=10,\n","                                output_shape=len(class_names)).to(device)"]},{"cell_type":"markdown","metadata":{"id":"ounUyuC22eNe"},"source":["# 4. Creating train_step() and test_step() functions and train() to combine them engine.py"]},{"cell_type":"markdown","metadata":{"id":"GIb-0mFl6kXL"},"source":["## Train model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1736855066717,"user":{"displayName":"","userId":""},"user_tz":-420},"id":"1XTf_GFp3pwX","outputId":"a1005450-1793-4bd7-d0a2-ffff1a798086"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/engine.py\n"]}],"source":["%%writefile going_modular/engine.py\n","\n","import torch\n","from torch import nn\n","from tqdm.auto import tqdm\n","# from timeit import default_timer as timer\n","from typing import Dict, List, Tuple\n","\n","def train_step(model: torch.nn.Module,\n","               dataloader: torch.utils.data.DataLoader,\n","               loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer,\n","               device: torch.device) -> Tuple[float, float]:\n","    # Put model in train mode\n","    model.train()\n","\n","    # Setup train loss, train accuracy\n","    train_loss, train_acc = 0, 0\n","\n","    # Loop through data loader data batches\n","    for batch, (x, y) in enumerate(dataloader):\n","      # Send x, y to device\n","      x, y = x.to(device), y.to(device)\n","\n","      # Forward\n","      y_pred = model(x)\n","\n","      # Calculate loss\n","      loss = loss_fn(y_pred, y)\n","      train_loss += loss.item()\n","\n","      # Optimizer zero grad\n","      optimizer.zero_grad()\n","\n","      # Loss backward\n","      loss.backward()\n","\n","      # Optimizer step\n","      optimizer.step()\n","\n","      # Calculate accuracy\n","      y_pred_class = torch.argmax(y_pred, dim=1)\n","      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n","\n","    # Average loss and accuracy per batch\n","    train_loss /= len(dataloader)\n","    train_acc /= len(dataloader)\n","    return train_loss, train_acc\n","\n","\n","\n","def test_step(model: torch.nn.Module,\n","              dataloader: torch.utils.data.DataLoader,\n","              loss_fn: torch.nn.Module,\n","              device: torch.device) -> Tuple[float, float]:\n","  # Put model in eval mode\n","  model.eval()\n","\n","  # Set up test loss, test accuracy\n","  test_loss, test_acc = 0, 0\n","\n","  # Turn on inference mode\n","  with torch.inference_mode():\n","    # Loop through data loader batches\n","    for batch, (x, y) in enumerate(dataloader):\n","      # Send x, y to device\n","      x, y = x.to(device), y.to(device)\n","\n","      # Forwardind\n","      y_logits = model(x)\n","\n","      # Calculate and accumulate loss\n","      loss = loss_fn(y_logits, y)\n","      test_loss += loss.item()\n","\n","      # Calculate and accumulate accuracy\n","      y_pred = torch.argmax(y_logits, dim=1)\n","      test_acc += (y_pred == y).sum().item()/len(y_pred)\n","\n","  # Calculate loss and accuracy per batch\n","  test_loss /= len(dataloader)\n","  test_acc /= len(dataloader)\n","  return test_loss, test_acc\n","\n","\n","def train(model: torch.nn.Module,\n","          train_dataloader: torch.utils.data.DataLoader,\n","          test_dataloader: torch.utils.data.DataLoader,\n","          loss_fn: torch.nn.Module,\n","          optimizer: torch.optim.Optimizer,\n","          epochs: int,\n","          device: torch.device) -> Dict[str, list]:\n","  # Create empty results dictionary\n","  results ={\n","      'train_loss': [],\n","      'train_acc': [],\n","      'test_loss': [],\n","      'test_acc': []\n","  }\n","\n","  # Loop through training and testing steps for numbers of epochs\n","  for epoch in tqdm(range(epochs)):\n","    train_loss, train_acc = train_step(model=model,\n","                                       dataloader=train_dataloader,\n","                                       loss_fn=loss_fn,\n","                                       optimizer=optimizer,\n","                                       device=device)\n","    test_loss, test_acc = test_step(model=model,\n","                                    dataloader=test_dataloader,\n","                                    loss_fn=loss_fn,\n","                                    device=device)\n","    # Print result per epoch\n","    print(\n","          f\"Epoch: {epoch+1} | \"\n","          f\"train_loss: {train_loss:.4f} | \"\n","          f\"train_acc: {train_acc:.4f} | \"\n","          f\"test_loss: {test_loss:.4f} | \"\n","          f\"test_acc: {test_acc:.4f}\"\n","      )\n","\n","    # Update results dictionary\n","    results[\"train_loss\"].append(train_loss)\n","    results[\"train_acc\"].append(train_acc)\n","    results[\"test_loss\"].append(test_loss)\n","    results[\"test_acc\"].append(test_acc)\n","\n","  return results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432,"referenced_widgets":["cc5ec275214e49098a1dd3d8da4fa011","9a8a0f9aefd3490b97b11e22337907f6","827021d6f5944e64a2b1c0e7f1420ef4","d9d4ce4a58794fc999ad03da339a7544","25f773dcb88444759c9c4b906977a16a","55c7334b1eb7480b9c5d95cab8f3bbfb","5a0f930ee3ec4eae8247c5a62f37fc32","f4ea0d5641104b29b8cfc4b204785b5b","1b3dfece8fbc4a88bb395c4b9d4a0307","8e235963045b4c4e84fc0a58468a0173","30c8b71891e04aa4925debc5a470af69"]},"executionInfo":{"elapsed":6758,"status":"ok","timestamp":1736855073472,"user":{"displayName":"","userId":""},"user_tz":-420},"id":"Z9b2P00S6m9I","outputId":"d5fbe2cf-7537-42b1-e175-176a9c962d59"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/5 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc5ec275214e49098a1dd3d8da4fa011"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1 | train_loss: 1.1063 | train_acc: 0.3047 | test_loss: 1.0983 | test_acc: 0.3011\n","Epoch: 2 | train_loss: 1.0998 | train_acc: 0.3281 | test_loss: 1.0697 | test_acc: 0.5417\n","Epoch: 3 | train_loss: 1.0869 | train_acc: 0.4883 | test_loss: 1.0808 | test_acc: 0.4924\n","Epoch: 4 | train_loss: 1.0843 | train_acc: 0.4023 | test_loss: 1.0608 | test_acc: 0.5833\n","Epoch: 5 | train_loss: 1.0662 | train_acc: 0.4102 | test_loss: 1.0653 | test_acc: 0.5644\n"]},{"output_type":"execute_result","data":{"text/plain":["{'train_loss': [1.1063191294670105,\n","  1.0998025238513947,\n","  1.0868679285049438,\n","  1.0843230187892914,\n","  1.066225990653038],\n"," 'train_acc': [0.3046875, 0.328125, 0.48828125, 0.40234375, 0.41015625],\n"," 'test_loss': [1.0983209212621052,\n","  1.0696989297866821,\n","  1.08075749874115,\n","  1.060782512029012,\n","  1.0653450886408489],\n"," 'test_acc': [0.30113636363636365,\n","  0.5416666666666666,\n","  0.49242424242424243,\n","  0.5833333333333334,\n","  0.5643939393939394]}"]},"metadata":{},"execution_count":8}],"source":["from going_modular import engine\n","loss_fn = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n","engine.train(model=model,\n","           train_dataloader=train_dataloader,\n","           test_dataloader=test_dataloader,\n","           loss_fn=loss_fn,\n","           optimizer=optimizer,\n","           epochs=5,\n","           device=device)"]},{"cell_type":"markdown","metadata":{"id":"LeQWKecu8LAM"},"source":["# 5. Creating function to save model (utils.py)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1736855073472,"user":{"displayName":"","userId":""},"user_tz":-420},"id":"-sfcbhGP65Mu","outputId":"007307d3-dae0-49ad-9b66-6e3355971595"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing going_modular/utils.py\n"]}],"source":["%%writefile going_modular/utils.py\n","from pathlib import Path\n","import torch\n","\n","def save_model(model: torch.nn.Module,\n","             target_dir: str,\n","             model_name: str):\n","  target_dir_path = Path(target_dir)\n","  target_dir_path.mkdir(parents=True,\n","                        exist_ok=True)\n","\n","  model_save_path = target_dir_path / model_name\n","\n","  print(f'Saving model to: {model_save_path}')\n","  torch.save(obj=model.state_dict(),\n","             f=model_save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":392,"status":"ok","timestamp":1736856690134,"user":{"displayName":"","userId":""},"user_tz":-420},"id":"R4W03Xh78yoG","outputId":"f554112c-0925-484d-a25c-6d6522d57d5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Saving model to: models/05_going_modular_script_mode_tinyvgg_model.pth\n"]}],"source":["from going_modular import utils\n","utils.save_model(model=model,\n","                 target_dir='models',\n","                 model_name='05_going_modular_script_mode_tinyvgg_model.pth')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/NGQ-Hiro/Basic_Pytorch/blob/master/Going_modular/Going_modular.ipynb","timestamp":1736856785729}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"cc5ec275214e49098a1dd3d8da4fa011":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a8a0f9aefd3490b97b11e22337907f6","IPY_MODEL_827021d6f5944e64a2b1c0e7f1420ef4","IPY_MODEL_d9d4ce4a58794fc999ad03da339a7544"],"layout":"IPY_MODEL_25f773dcb88444759c9c4b906977a16a"}},"9a8a0f9aefd3490b97b11e22337907f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55c7334b1eb7480b9c5d95cab8f3bbfb","placeholder":"​","style":"IPY_MODEL_5a0f930ee3ec4eae8247c5a62f37fc32","value":"100%"}},"827021d6f5944e64a2b1c0e7f1420ef4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4ea0d5641104b29b8cfc4b204785b5b","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b3dfece8fbc4a88bb395c4b9d4a0307","value":5}},"d9d4ce4a58794fc999ad03da339a7544":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e235963045b4c4e84fc0a58468a0173","placeholder":"​","style":"IPY_MODEL_30c8b71891e04aa4925debc5a470af69","value":" 5/5 [00:06&lt;00:00,  1.06s/it]"}},"25f773dcb88444759c9c4b906977a16a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55c7334b1eb7480b9c5d95cab8f3bbfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a0f930ee3ec4eae8247c5a62f37fc32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4ea0d5641104b29b8cfc4b204785b5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b3dfece8fbc4a88bb395c4b9d4a0307":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8e235963045b4c4e84fc0a58468a0173":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30c8b71891e04aa4925debc5a470af69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}